

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Morphological operations &mdash; Machine Vision Toolbox 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Blob features" href="blobs.html" />
    <link rel="prev" title="Spatial operators" href="kernel.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> Machine Vision Toolbox
          

          
            
            <img src="_static/VisionToolboxLogo_CircBlack.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="image.html">Image processing</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="image.html#function-reference">Function reference</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="imageproc.html">Image processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="imagecolor.html">Color operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="kernel.html">Spatial operators</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Morphological operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="blobs.html">Blob features</a></li>
<li class="toctree-l3"><a class="reference internal" href="features2d.html">2D image features</a></li>
<li class="toctree-l3"><a class="reference internal" href="camera.html">Camera geometry</a></li>
<li class="toctree-l3"><a class="reference internal" href="imageio.html">Image i/o</a></li>
<li class="toctree-l3"><a class="reference internal" href="color.html">Color</a></li>
<li class="toctree-l3"><a class="reference internal" href="shapes.html">Canonic 3D shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="graphics.html">Graphics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="color.html">Color</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Machine Vision Toolbox</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="image.html">Image processing</a> &raquo;</li>
        
      <li>Morphological operations</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/morph.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <div class="rst-breadcrumbs-buttons" role="navigation" aria-label="breadcrumb navigation">
      
        <a href="blobs.html" class="btn btn-neutral float-right" title="Blob features" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="kernel.html" class="btn btn-neutral float-left" title="Spatial operators" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
  </div>
  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="morphological-operations">
<h1>Morphological operations<a class="headerlink" href="#morphological-operations" title="Permalink to this headline">¶</a></h1>
<p>These functions perform image processing operations on grey-scale and color images.</p>
<dl class="py class">
<dt id="machinevisiontoolbox.Image">
<em class="property">class </em><code class="sig-prename descclassname">machinevisiontoolbox.</code><code class="sig-name descname">Image</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">arg</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">colororder</span><span class="o">=</span><span class="default_value">'BGR'</span></em>, <em class="sig-param"><span class="n">iscolor</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">checksize</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">checktype</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/machinevisiontoolbox/Image.html#Image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#machinevisiontoolbox.Image" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt id="machinevisiontoolbox.Image.close">
<code class="sig-name descname">close</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">se</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.close" title="Permalink to this definition">¶</a></dt>
<dd><p>Morphological closing</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>se</strong> (<em>numpy array</em><em> (</em><em>S</em><em>,</em><em>T</em><em>)</em><em>, </em><em>where S &lt; N and T &lt; H</em>) – structuring element</p></li>
<li><p><strong>n</strong> (<em>integer</em>) – number of times to apply the operation</p></li>
<li><p><strong>opt</strong> (<em>string</em>) – option specifying the type of border behaviour</p></li>
</ul>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>Image</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Image instance (N,H,3) or (N,H)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.iclose(se,</span> <span class="pre">opt)</span></code> is the image after morphological closing with
structuring element <code class="docutils literal notranslate"><span class="pre">se</span></code>. This is a morphological dilation followed
by erosion.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.iclose(se,</span> <span class="pre">n,</span> <span class="pre">opt)</span></code> as above, but the structuring element
<code class="docutils literal notranslate"><span class="pre">se</span></code> is applied <code class="docutils literal notranslate"><span class="pre">n</span></code> times, that is <code class="docutils literal notranslate"><span class="pre">n</span></code> dilations followed by
<code class="docutils literal notranslate"><span class="pre">n</span></code> erosions.</p></li>
</ul>
<dl class="field-list">
<dt class="field-odd">Options</dt>
<dd class="field-odd"><ul class="simple">
<li><p>‘border’    the border value is replicated (default)</p></li>
<li><p>‘none’      pixels beyond the border not included in the window</p></li>
<li><p>‘trim’      output is not computed for pixels where the</p></li>
</ul>
<p>structuring element crosses the image border, hence output
image has reduced dimensions TODO</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>For binary image an opening operation can be used to eliminate
small white noise regions.</p></li>
<li><p>Cheaper to apply a smaller structuring element multiple times
than one large one, the effective structuing element is the
Minkowski sum of the structuring element with itself N times.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.5, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.dilate">
<code class="sig-name descname">dilate</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">se</span></em>, <em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">opt</span><span class="o">=</span><span class="default_value">'replicate'</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.dilate" title="Permalink to this definition">¶</a></dt>
<dd><p>Morphological dilation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>se</strong> (<em>numpy array</em><em> (</em><em>S</em><em>,</em><em>T</em><em>)</em><em>, </em><em>where S &lt; N and T &lt; H</em>) – structuring element</p></li>
<li><p><strong>n</strong> (<em>integer</em>) – number of times to apply the dilation</p></li>
<li><p><strong>opt</strong> (<em>string :return</em>) – option specifying the type of dilation</p></li>
</ul>
</dd>
</dl>
<p>out: Image with dilated binary image values
:rtype: Image instance</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.dilate(se,</span> <span class="pre">opt)</span></code> is the image after morphological dilation with
structuring element <code class="docutils literal notranslate"><span class="pre">se</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.dilate(se,</span> <span class="pre">n,</span> <span class="pre">opt)</span></code> as above, but the structruring element
<code class="docutils literal notranslate"><span class="pre">se</span></code> is applied <code class="docutils literal notranslate"><span class="pre">n</span></code> times, that is <code class="docutils literal notranslate"><span class="pre">n</span></code> dilations.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Options:</dt>
<dd class="field-odd"><ul class="simple">
<li><p>‘replicate’     the border value is replicated (default)</p></li>
<li><p>‘none’          pixels beyond the border are not included in the
window</p></li>
<li><p>‘trim’          output is not computed for pixels where the
structuring element crosses the image border, hence output image
has reduced dimensions TODO</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Cheaper to apply a smaller structuring element multiple times</p></li>
</ul>
<p>than one large one, the effective structuing element is the
Minkowski sum of the structuring element with itself N times.</p>
</div>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.5, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.endpoint">
<code class="sig-name descname">endpoint</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.endpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Find end points on a binary skeleton image</p>
<dl class="field-list simple">
<dt class="field-odd">Return out</dt>
<dd class="field-odd"><p>Image with endpoints</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Image instance (N,H,3) or (N,H)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.endpoint()</span></code> is the binary image where pixels are set if the
corresponding pixel in the binary image <code class="docutils literal notranslate"><span class="pre">im</span></code> is the end point of a
single-pixel wide line such as found in an image skeleton.  Computed
using the hit-or-miss morphological operator.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.5.3, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.erode">
<code class="sig-name descname">erode</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">se</span></em>, <em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">opt</span><span class="o">=</span><span class="default_value">'replicate'</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.erode" title="Permalink to this definition">¶</a></dt>
<dd><p>Morphological erosion</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>se</strong> (<em>numpy array</em><em> (</em><em>S</em><em>,</em><em>T</em><em>)</em><em>, </em><em>where S &lt; N and T &lt; H</em>) – structuring element</p></li>
<li><p><strong>n</strong> (<em>integer</em>) – number of times to apply the erosion</p></li>
<li><p><strong>opt</strong> (<em>string</em>) – option specifying the type of erosion</p></li>
</ul>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>Image with eroded binary image pixel values</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.erode(se,</span> <span class="pre">opt)</span></code> is the image after morphological erosion with
structuring element <code class="docutils literal notranslate"><span class="pre">se</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.erode(se,</span> <span class="pre">n,</span> <span class="pre">opt)</span></code> as above, but the structruring element
<code class="docutils literal notranslate"><span class="pre">se</span></code> is applied <code class="docutils literal notranslate"><span class="pre">n</span></code> times, that is <code class="docutils literal notranslate"><span class="pre">n</span></code> erosions.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Options</dt>
<dd class="field-odd"><ul class="simple">
<li><p>‘replicate’     the border value is replicated (default)</p></li>
<li><p>‘none’          pixels beyond the border are not included in the
window</p></li>
<li><p>‘trim’          output is not computed for pixels where the
structuring element crosses the image border, hence output image
has reduced dimensions TODO</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Cheaper to apply a smaller structuring element multiple times
than one large one, the effective structuing element is the
Minkowski sum of the structuring element with itself N times.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.5, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.hitormiss">
<code class="sig-name descname">hitormiss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">s1</span></em>, <em class="sig-param"><span class="n">s2</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.hitormiss" title="Permalink to this definition">¶</a></dt>
<dd><p>Hit or miss transform</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>s1</strong> (<em>numpy array</em><em> (</em><em>S</em><em>,</em><em>T</em><em>)</em><em>, </em><em>where S &lt; N and T &lt; H</em>) – structuring element 1</p></li>
<li><p><strong>s2</strong> (<em>numpy array</em><em> (</em><em>S</em><em>,</em><em>T</em><em>)</em><em>, </em><em>where S &lt; N and T &lt; H</em>) – structuring element 2</p></li>
</ul>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>Image</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.hitormiss(s1,</span> <span class="pre">s2)</span></code> is the image with the hit-or-miss transform
of the binary image with the structuring element <code class="docutils literal notranslate"><span class="pre">s1</span></code>. Unlike
standard morphological operations, <code class="docutils literal notranslate"><span class="pre">s1</span></code> has three possible values:
0, 1 and don’t care (represented by nans).</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.5, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.humoments">
<code class="sig-name descname">humoments</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.humoments" title="Permalink to this definition">¶</a></dt>
<dd><p>Hu image moments
:param im: binary image
:type im: numpy array
:return: hu image moments
:type: dictionary</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.humoments()</span></code> are the Hu image moments of the imag as a
dictionary.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>image is assumed to be a binary image of a single connected
region</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>M-K. Hu, Visual pattern recognition by moment invariants. IRE
Trans. on Information Theory, IT-8:pp. 179-187, 1962.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.label">
<code class="sig-name descname">label</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">conn</span><span class="o">=</span><span class="default_value">8</span></em>, <em class="sig-param"><span class="n">outtype</span><span class="o">=</span><span class="default_value">'int32'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.label" title="Permalink to this definition">¶</a></dt>
<dd><p>Label an image</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>conn</strong> (<em>integer</em>) – connectivity, 4 or 8</p></li>
<li><p><strong>ltype</strong> (<em>string</em>) – output image type</p></li>
</ul>
</dd>
<dt class="field-even">Return out_c</dt>
<dd class="field-even"><p>n_components</p>
</dd>
<dt class="field-odd">Rtype out_c</dt>
<dd class="field-odd"><p>int</p>
</dd>
<dt class="field-even">Return labels</dt>
<dd class="field-even"><p>labelled image</p>
</dd>
<dt class="field-odd">Rtype labels</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.label()</span></code> is a label image that indicates connected components
within the image. Each pixel is an integer label that indicates which
connected region the corresponding pixel in image belongs to.  Region
labels are in the range 1 to <code class="docutils literal notranslate"><span class="pre">n_components</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.label(conn)</span></code> as above, with the connectivity specified. 4 or 8.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.label(outtype)</span></code> as above, with the output type specified as
either int32 or uint16.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Converts a color image to greyscale.</p></li>
<li><p>This algorithm is variously known as region labelling,
connectivity analysis, connected component analysis,
blob labelling.</p></li>
<li><p>All pixels within a region have the same value (or class).</p></li>
<li><p>The image can be binary or greyscale.</p></li>
<li><p>Connectivity is only performed in 2 dimensions.</p></li>
<li><p>Connectivity is performed using 8 nearest neighbours by default.</p></li>
<li><p>8-way connectivity introduces ambiguities, a chequerboard is
two blobs.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.moments">
<code class="sig-name descname">moments</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">binary</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.moments" title="Permalink to this definition">¶</a></dt>
<dd><p>Image moments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>im</strong> (<em>numpy array</em>) – binary image</p></li>
<li><p><strong>binary</strong> (<em>bool</em>) – if True, all non-zero pixels are treated as 1’s</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>image moments</p>
</dd>
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>dictionary</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.moments()</span></code> are the image moments of the image, supplied as a
dictionary.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.moments(binary)</span></code> as above, but if True, all non-zero pixels are
treated as 1’s in the image.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Converts a color image to greyscale.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.mpq">
<code class="sig-name descname">mpq</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.mpq" title="Permalink to this definition">¶</a></dt>
<dd><p>Image moments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>integer</em>) – p’th exponent</p></li>
<li><p><strong>q</strong> (<em>integer</em>) – q’th exponent</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>moment</p>
</dd>
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of scalars (same as image type)</p>
</dd>
</dl>
<p>-<code class="docutils literal notranslate"><span class="pre">IM.mpq(p,</span> <span class="pre">q)</span></code> is the pq’th moment of the image. That is, the sum of
<code class="docutils literal notranslate"><span class="pre">im(x,y)</span> <span class="pre">.</span> <span class="pre">x^p</span> <span class="pre">.</span> <span class="pre">y^q</span></code></p>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.npq">
<code class="sig-name descname">npq</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.npq" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalized central image moments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>integer</em>) – p’th exponent</p></li>
<li><p><strong>q</strong> (<em>integer</em>) – q’th exponent</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>moment</p>
</dd>
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of scalar (same as image type)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.npq(p,</span> <span class="pre">q)</span></code> is the pq’th normalized central moment of the image.
That is, the sum of upq(im,p,q) / mpq(im,0,0)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.open">
<code class="sig-name descname">open</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">se</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.open" title="Permalink to this definition">¶</a></dt>
<dd><p>Morphological opening</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>se</strong> (<em>numpy array</em><em> (</em><em>S</em><em>,</em><em>T</em><em>)</em><em>, </em><em>where S &lt; N and T &lt; H</em>) – structuring element</p></li>
<li><p><strong>n</strong> (<em>integer</em>) – number of times to apply the dilation</p></li>
<li><p><strong>opt</strong> (<em>string</em>) – option specifying the type of dilation</p></li>
</ul>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>Image</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.iopen(se,</span> <span class="pre">opt)</span></code> is the image after morphological opening with
structuring element <code class="docutils literal notranslate"><span class="pre">se</span></code>. This is a morphological erosion followed
by dilation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.iopen(se,</span> <span class="pre">n,</span> <span class="pre">opt)</span></code> as above, but the structruring element
<code class="docutils literal notranslate"><span class="pre">se</span></code> is applied <code class="docutils literal notranslate"><span class="pre">n</span></code> times, that is <code class="docutils literal notranslate"><span class="pre">n</span></code> erosions followed by
<code class="docutils literal notranslate"><span class="pre">n</span></code> dilations.</p></li>
</ul>
<dl class="field-list">
<dt class="field-odd">Options</dt>
<dd class="field-odd"><ul class="simple">
<li><p>‘border’    the border value is replicated (default)</p></li>
<li><p>‘none’      pixels beyond the border not included in the window</p></li>
<li><p>‘trim’      output is not computed for pixels where the</p></li>
</ul>
<p>structuring element crosses the image border, hence output
image has reduced dimensions TODO</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>For binary image an opening operation can be used to eliminate
small white noise regions.</p></li>
<li><p>Cheaper to apply a smaller structuring element multiple times
than one large one, the effective structuing element is the
Minkowski sum of the structuring element with itself N times.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.5, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.thin">
<code class="sig-name descname">thin</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">delay</span><span class="o">=</span><span class="default_value">0.0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.thin" title="Permalink to this definition">¶</a></dt>
<dd><p>Morphological skeletonization</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>delay</strong> (<em>float</em>) – seconds between each iteration of display</p>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>Image</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Image instance (N,H,3) or (N,H)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.thin()</span></code> is the image as a binary skeleton of the binary image
IM. Any non-zero region is replaced by a network of single-pixel wide
lines.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.thin(delay)</span></code> as above but graphically displays each iteration
of the skeletonization algorithm with a pause of <code class="docutils literal notranslate"><span class="pre">delay</span></code> seconds
between each iteration. TODO</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.5, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.triplepoint">
<code class="sig-name descname">triplepoint</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.triplepoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Find triple points</p>
<dl class="field-list simple">
<dt class="field-odd">Return out</dt>
<dd class="field-odd"><p>Image with triplepoints</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Image instance (N,H,3) or (N,H)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.triplepoint()</span></code> is the binary image where pixels are set if the
corresponding pixel in the binary image  is a triple point, that is
where three single-pixel wide line intersect. These are the Voronoi
points in an image skeleton.  Computed using the hit-or-miss
morphological operator.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.5.3, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.upq">
<code class="sig-name descname">upq</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">p</span></em>, <em class="sig-param"><span class="n">q</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.upq" title="Permalink to this definition">¶</a></dt>
<dd><p>Central image moments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>integer</em>) – p’th exponent</p></li>
<li><p><strong>q</strong> (<em>integer</em>) – q’th exponent</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>moment</p>
</dd>
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list of scalar (same as image type)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.upq(p,</span> <span class="pre">q)</span></code> is the pq’th central moment of the image. That is,
the sum of <code class="docutils literal notranslate"><span class="pre">im(x,y)</span> <span class="pre">.</span> <span class="pre">(x</span> <span class="pre">-</span> <span class="pre">x0)^p</span> <span class="pre">.</span> <span class="pre">(y</span> <span class="pre">-</span> <span class="pre">y0)^q</span></code> where (x0, y0) is
the centroid</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="blobs.html" class="btn btn-neutral float-right" title="Blob features" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="kernel.html" class="btn btn-neutral float-left" title="Spatial operators" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 
      <span class="lastupdated">
        Last updated on 28-Jan-2021.
      </span>

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>