

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Spatial operators &mdash; Machine Vision Toolbox 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Morphological operations" href="morph.html" />
    <link rel="prev" title="Color operations" href="imagecolor.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> Machine Vision Toolbox
          

          
            
            <img src="_static/VisionToolboxLogo_CircBlack.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="image.html">Image processing</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="image.html#function-reference">Function reference</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="imageproc.html">Image processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="imagecolor.html">Color operations</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Spatial operators</a></li>
<li class="toctree-l3"><a class="reference internal" href="morph.html">Morphological operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="blobs.html">Blob features</a></li>
<li class="toctree-l3"><a class="reference internal" href="features2d.html">2D image features</a></li>
<li class="toctree-l3"><a class="reference internal" href="camera.html">Camera geometry</a></li>
<li class="toctree-l3"><a class="reference internal" href="imageio.html">Image i/o</a></li>
<li class="toctree-l3"><a class="reference internal" href="color.html">Color</a></li>
<li class="toctree-l3"><a class="reference internal" href="shapes.html">Canonic 3D shapes</a></li>
<li class="toctree-l3"><a class="reference internal" href="graphics.html">Graphics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="color.html">Color</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Machine Vision Toolbox</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="image.html">Image processing</a> &raquo;</li>
        
      <li>Spatial operators</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/kernel.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <div class="rst-breadcrumbs-buttons" role="navigation" aria-label="breadcrumb navigation">
      
        <a href="morph.html" class="btn btn-neutral float-right" title="Morphological operations" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="imagecolor.html" class="btn btn-neutral float-left" title="Color operations" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
  </div>
  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="spatial-operators">
<h1>Spatial operators<a class="headerlink" href="#spatial-operators" title="Permalink to this headline">¶</a></h1>
<p>These functions perform image processing operations on grey-scale and color images.</p>
<dl class="py class">
<dt id="machinevisiontoolbox.Image">
<em class="property">class </em><code class="sig-prename descclassname">machinevisiontoolbox.</code><code class="sig-name descname">Image</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">arg</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">colororder</span><span class="o">=</span><span class="default_value">'BGR'</span></em>, <em class="sig-param"><span class="n">iscolor</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">checksize</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">checktype</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/machinevisiontoolbox/Image.html#Image"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#machinevisiontoolbox.Image" title="Permalink to this definition">¶</a></dt>
<dd><dl class="py method">
<dt id="machinevisiontoolbox.Image.canny">
<code class="sig-name descname">canny</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">th0</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">th1</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.canny" title="Permalink to this definition">¶</a></dt>
<dd><p>Canny edge detection</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma</strong> (<em>float</em>) – standard deviation for Gaussian kernel smoothing</p></li>
<li><p><strong>th0</strong> (<em>float</em>) – lower threshold</p></li>
<li><p><strong>th1</strong> (<em>float</em>) – upper threshold</p></li>
</ul>
</dd>
<dt class="field-even">Return E</dt>
<dd class="field-even"><p>Image with edge image</p>
</dd>
<dt class="field-odd">Rtype E</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.canny()</span></code> is an edge image obtained using the Canny edge
detector algorithm.  Hysteresis filtering is applied to the gradient
image: edge pixels &gt; <code class="docutils literal notranslate"><span class="pre">th1</span></code> are connected to adjacent pixels &gt;
<code class="docutils literal notranslate"><span class="pre">th0</span></code>, those below <code class="docutils literal notranslate"><span class="pre">th0</span></code> are set to zero.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.canny(sigma,</span> <span class="pre">th0,</span> <span class="pre">th1)</span></code> as above, but the standard deviation of
the Gaussian smoothing, <code class="docutils literal notranslate"><span class="pre">sigma</span></code>, lower and upper thresholds
<code class="docutils literal notranslate"><span class="pre">th0</span></code>, <code class="docutils literal notranslate"><span class="pre">th1</span></code> can be specified</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Produces a zero image with single pixel wide edges having
non-zero values.</p></li>
<li><p>Larger values correspond to stronger edges.</p></li>
<li><p>If th1 is zero then no hysteresis filtering is performed.</p></li>
<li><p>A color image is automatically converted to greyscale first.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>“A Computational Approach To Edge Detection”, J. Canny,
IEEE Trans. Pattern Analysis and Machine Intelligence,
8(6):679–698, 1986.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.convolve">
<code class="sig-name descname">convolve</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">K</span></em>, <em class="sig-param"><span class="n">optmode</span><span class="o">=</span><span class="default_value">'same'</span></em>, <em class="sig-param"><span class="n">optboundary</span><span class="o">=</span><span class="default_value">'wrap'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.convolve" title="Permalink to this definition">¶</a></dt>
<dd><p>Image convolution</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>K</strong> (<em>numpy array</em>) – kernel</p></li>
<li><p><strong>optmode</strong> (<em>string</em>) – option for convolution</p></li>
<li><p><strong>optboundary</strong> (<em>string</em>) – option for boundary handling</p></li>
</ul>
</dd>
<dt class="field-even">Return C</dt>
<dd class="field-even"><p>Image convolved image</p>
</dd>
<dt class="field-odd">Rtype C</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.convolve(K)</span></code> is the convolution of image with the kernel <code class="docutils literal notranslate"><span class="pre">K</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.convolve(K,</span> <span class="pre">optmode)</span></code> as above but specifies the convolution
mode. See scipy.signal.convolve2d for details, mode options below</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.convolve(K,</span> <span class="pre">optboundary)</span></code> as above but specifies the boundary
handling options</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Options</dt>
<dd class="field-odd"><ul class="simple">
<li><p>‘same’    output image is same size as input image (default)</p></li>
<li><p>‘full’    output image is larger than the input image</p></li>
<li><p>‘valid’   output image is smaller than the input image, and
contains only valid pixels TODO</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>If the image is color (has multiple planes) the kernel is
applied to each plane, resulting in an output image with the same
number of planes.</p></li>
<li><p>If the kernel has multiple planes, the image is convolved with
each plane of the kernel, resulting in an output image with the
same number of planes.</p></li>
<li><p>This function is a convenience wrapper for the MATLAB function
CONV2.</p></li>
<li><p>Works for double, uint8 or uint16 images.  Image and kernel must
be of the same type and the result is of the same type.</p></li>
<li><p>This function replaces iconv().</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.4, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.kcircle">
<em class="property">static </em><code class="sig-name descname">kcircle</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">r</span></em>, <em class="sig-param"><span class="n">hw</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.kcircle" title="Permalink to this definition">¶</a></dt>
<dd><p>Circular structuring element</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>r</strong> (<em>float</em><em>, </em><em>2-tuple</em><em> or </em><em>2-element vector of floats</em>) – radius of circle structuring element, or 2-vector (see below)</p></li>
<li><p><strong>hw</strong> (<em>integer</em>) – half-width of kernel</p></li>
</ul>
</dd>
<dt class="field-even">Return k</dt>
<dd class="field-even"><p>kernel</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array (2 * 3 * sigma + 1, 2 * 3 * sigma + 1)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.kcircle(r)</span></code> is a square matrix <code class="docutils literal notranslate"><span class="pre">(w,w)</span></code> where <code class="docutils literal notranslate"><span class="pre">w=2r+1</span></code> of
zeros with a maximal centred circular region of radius <code class="docutils literal notranslate"><span class="pre">r</span></code> pixels
set to one.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.kcircle(r,w)</span></code> as above but the dimension of the kernel is
explicitly specified.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">r</span></code> is a 2-element vector the result is an annulus of ones,
and the two numbers are interpretted as inner and outer radii.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.kdgauss">
<em class="property">static </em><code class="sig-name descname">kdgauss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sigma</span></em>, <em class="sig-param"><span class="n">hw</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.kdgauss" title="Permalink to this definition">¶</a></dt>
<dd><p>Derivative of Gaussian kernel</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma1</strong> (<em>float</em>) – standard deviation of first Gaussian kernel</p></li>
<li><p><strong>hw</strong> (<em>integer</em>) – half-width of kernel</p></li>
</ul>
</dd>
<dt class="field-even">Return k</dt>
<dd class="field-even"><p>kernel</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array (2 * 3 * sigma + 1, 2 * 3 * sigma + 1)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.kdgauss(sigma)</span></code> is a 2-dimensional derivative of Gaussian
kernel <code class="docutils literal notranslate"><span class="pre">(w,w)</span></code> of width (standard deviation) sigma and centred
within the matrix <code class="docutils literal notranslate"><span class="pre">k</span></code> whose half-width <code class="docutils literal notranslate"><span class="pre">hw</span> <span class="pre">=</span> <span class="pre">3xsigma</span></code> and
<code class="docutils literal notranslate"><span class="pre">w=2xhw+1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.kdgauss(sigma,</span> <span class="pre">hw)</span></code> as above but the half-width is explictly
specified.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>This kernel is the horizontal derivative of the Gaussian, dG/dx.</p></li>
<li><p>The vertical derivative, dG/dy, is k’.</p></li>
<li><p>This kernel is an effective edge detector.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.kdog">
<em class="property">static </em><code class="sig-name descname">kdog</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sigma1</span></em>, <em class="sig-param"><span class="n">sigma2</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">hw</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.kdog" title="Permalink to this definition">¶</a></dt>
<dd><p>Difference of Gaussians kernel</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma1</strong> (<em>float</em>) – standard deviation of first Gaussian kernel</p></li>
<li><p><strong>sigma2</strong> (<em>float</em>) – standard deviation of second Gaussian kernel</p></li>
<li><p><strong>hw</strong> (<em>integer</em>) – half-width of Gaussian kernel</p></li>
</ul>
</dd>
<dt class="field-even">Return k</dt>
<dd class="field-even"><p>kernel</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.kdog(sigma1)</span></code> is a 2-dimensional difference of Gaussian kernel
equal to <code class="docutils literal notranslate"><span class="pre">kgauss(sigma1)</span> <span class="pre">-</span> <span class="pre">kgauss(sigma2)</span></code>, where <code class="docutils literal notranslate"><span class="pre">sigma1</span></code> &gt;
<code class="docutils literal notranslate"><span class="pre">sigma2.</span> <span class="pre">By</span> <span class="pre">default,</span> <span class="pre">``sigma2</span> <span class="pre">=</span> <span class="pre">1.6</span> <span class="pre">*</span> <span class="pre">sigma1</span></code>.  The kernel is
centred within the matrix <code class="docutils literal notranslate"><span class="pre">k</span></code> whose half-width <code class="docutils literal notranslate"><span class="pre">hw</span> <span class="pre">=</span> <span class="pre">3xsigma1</span></code>
and full width of the kernel is <code class="docutils literal notranslate"><span class="pre">2xhw+1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.kdog(sigma1,</span> <span class="pre">sigma2)</span></code> as above but sigma2 is specified
directly.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.kdog(sigma1,</span> <span class="pre">sigma2,</span> <span class="pre">hw)</span></code> as above but the kernel half-width is
specified</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>This kernel is similar to the Laplacian of Gaussian and is often
used as an efficient approximation.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.kgauss">
<em class="property">static </em><code class="sig-name descname">kgauss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sigma</span></em>, <em class="sig-param"><span class="n">hw</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.kgauss" title="Permalink to this definition">¶</a></dt>
<dd><p>Gaussian kernel</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma</strong> (<em>float</em>) – standard deviation of Gaussian kernel</p></li>
<li><p><strong>hw</strong> (<em>integer</em>) – width of the kernel</p></li>
</ul>
</dd>
<dt class="field-even">Return k</dt>
<dd class="field-even"><p>kernel</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array (N,H)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.kgauss(sigma)</span></code> is a 2-dimensional Gaussian kernel of standard
deviation <code class="docutils literal notranslate"><span class="pre">sigma</span></code>, and centred within the matrix <code class="docutils literal notranslate"><span class="pre">k</span></code> whose
half-width is <code class="docutils literal notranslate"><span class="pre">hw=2*sigma</span></code> and <code class="docutils literal notranslate"><span class="pre">w=2*hw+1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.kgauss(sigma,</span> <span class="pre">hw)</span></code> as above but the half-width <code class="docutils literal notranslate"><span class="pre">hw</span></code> is
specified.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The volume under the Gaussian kernel is one.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.klaplace">
<em class="property">static </em><code class="sig-name descname">klaplace</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.klaplace" title="Permalink to this definition">¶</a></dt>
<dd><p>Laplacian kernel</p>
<dl class="field-list simple">
<dt class="field-odd">Return k</dt>
<dd class="field-odd"><p>kernel</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>numpy array (3,3)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.klaplace()</span></code> is the Laplacian kernel:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}K = \begin{bmatrix}
    0 &amp; 1 &amp; 0 \\
    1 &amp; -4 &amp; 1 \\
    0 &amp; 1 &amp; 0
    \end{bmatrix}\end{split}\]</div>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>This kernel has an isotropic response to image gradient.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.klog">
<em class="property">static </em><code class="sig-name descname">klog</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sigma</span></em>, <em class="sig-param"><span class="n">hw</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.klog" title="Permalink to this definition">¶</a></dt>
<dd><p>Laplacian of Gaussian kernel</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma1</strong> (<em>float</em>) – standard deviation of first Gaussian kernel</p></li>
<li><p><strong>hw</strong> (<em>integer</em>) – half-width of kernel</p></li>
</ul>
</dd>
<dt class="field-even">Return k</dt>
<dd class="field-even"><p>kernel</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>numpy array (2 * 3 * sigma + 1, 2 * 3 * sigma + 1)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.klog(sigma)</span></code> is a 2-dimensional Laplacian of Gaussian kernel of
width (standard deviation) sigma and centred within the matrix <code class="docutils literal notranslate"><span class="pre">k</span></code>
whose half-width is <code class="docutils literal notranslate"><span class="pre">hw=3xsigma</span></code>, and <code class="docutils literal notranslate"><span class="pre">w=2xhw+1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.klog(sigma,</span> <span class="pre">hw)</span></code> as above but the half-width <code class="docutils literal notranslate"><span class="pre">w</span></code> is
specified.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.ksobel">
<em class="property">static </em><code class="sig-name descname">ksobel</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.ksobel" title="Permalink to this definition">¶</a></dt>
<dd><p>Sobel edge detector</p>
<dl class="field-list simple">
<dt class="field-odd">Return k</dt>
<dd class="field-odd"><p>kernel</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>numpy array (3,3)</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.ksobel()</span></code> is the Sobel x-derivative kernel:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}K = \frac{1}{8} \begin{bmatrix}
    1 &amp; 0 &amp; -1 \\
    2 &amp; 0 &amp; -2 \\
    1 &amp; 0 &amp; -1
    \end{bmatrix}\end{split}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>This kernel is an effective vertical-edge detector</p></li>
<li><p>The y-derivative (horizontal-edge) kernel is K’</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.ncc">
<code class="sig-name descname">ncc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">im2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.ncc" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalised cross correlation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>im2</strong> (<em>numpy array</em>) – image 2</p>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>ncc</p>
</dd>
<dt class="field-odd">Rtype out</dt>
<dd class="field-odd"><p>scalar</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.ncc(im2)</span></code> is the normalized cross-correlation between the two
equally sized image patches image and <code class="docutils literal notranslate"><span class="pre">im2</span></code>. The result is a scalar
in the interval -1 (non match) to 1 (perfect match) that indicates
similarity.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>A value of 1 indicates identical pixel patterns.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">ncc</span></code> similarity measure is invariant to scale changes in
image intensity.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.pyramid">
<code class="sig-name descname">pyramid</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sigma</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">N</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.pyramid" title="Permalink to this definition">¶</a></dt>
<dd><p>Pyramidal image decomposition</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma</strong> (<em>float</em>) – standard deviation of Gaussian kernel</p></li>
<li><p><strong>N</strong> (<em>int</em>) – number of pyramid levels to be computed</p></li>
</ul>
</dd>
<dt class="field-even">Return pyrimlist</dt>
<dd class="field-even"><p>list of Images for each pyramid level computed</p>
</dd>
<dt class="field-odd">Rtype pyrimlist</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.pyramid()</span></code> is a pyramid decomposition of image using Gaussian
smoothing with standard deviation of 1. The return is a list array of
images each one having dimensions half that of the previous image.
The pyramid is computed down to a non-halvable image size.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.pyramid(sigma)</span></code> as above but the Gaussian standard deviation is
<code class="docutils literal notranslate"><span class="pre">sigma</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.pyramid(sigma,</span> <span class="pre">N)</span></code> as above but only <code class="docutils literal notranslate"><span class="pre">N</span></code> levels of the
pyramid are computed.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Converts a color image to greyscale.</p></li>
<li><p>Works for greyscale images only.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.rank">
<code class="sig-name descname">rank</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">se</span></em>, <em class="sig-param"><span class="n">rank</span><span class="o">=</span><span class="default_value">- 1</span></em>, <em class="sig-param"><span class="n">opt</span><span class="o">=</span><span class="default_value">'replicate'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.rank" title="Permalink to this definition">¶</a></dt>
<dd><p>Rank filter</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>se</strong> (<em>numpy array</em>) – structuring element</p></li>
<li><p><strong>rank</strong> (<em>integer</em>) – rank of filter</p></li>
<li><p><strong>opt</strong> (<em>string</em>) – border option</p></li>
</ul>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>Image  after rank filter applied to every pixel</p>
</dd>
<dt class="field-odd">Rtype out</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.rank(se,</span> <span class="pre">rank)</span></code> is a rank filtered version of image.  Only
pixels corresponding to non-zero elements of the structuring element
<code class="docutils literal notranslate"><span class="pre">se</span></code> are ranked and the <code class="docutils literal notranslate"><span class="pre">rank</span></code>’ed value in rank becomes the
corresponding output pixel value.  The highest rank, the maximum, is
<code class="docutils literal notranslate"><span class="pre">rank=-1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.rank(se,</span> <span class="pre">rank,</span> <span class="pre">opt)</span></code> as above but the processing of edge pixels
can be controlled.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Options</dt>
<dd class="field-odd"><ul class="simple">
<li><p>‘replicate’     the border value is replicated (default)</p></li>
<li><p>‘none’          pixels beyond the border are not included in
the window</p></li>
<li><p>‘trim’          output is not computed for pixels where the
structuring element crosses the image border, hence output image
has reduced dimensions TODO</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The structuring element should have an odd side length.</p></li>
<li><p>The input can be logical, uint8, uint16, float or double, the
output is always double</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.sad">
<code class="sig-name descname">sad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">im2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.sad" title="Permalink to this definition">¶</a></dt>
<dd><p>Sum of absolute differences</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>im2</strong> (<em>numpy array</em>) – image 2</p>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>sad</p>
</dd>
<dt class="field-odd">Rtype out</dt>
<dd class="field-odd"><p>scalar</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.sad(im2)</span></code> is the sum of absolute differences between the two
equally sized image patches of image and <code class="docutils literal notranslate"><span class="pre">im2</span></code>. The result is a
scalar that indicates image similarity, a value of 0 indicates
identical pixel patterns and is increasingly positive as image
dissimilarity increases.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.similarity">
<code class="sig-name descname">similarity</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">T</span></em>, <em class="sig-param"><span class="n">metric</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Locate template in image</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>T</strong> (<em>numpy array</em>) – template image</p></li>
<li><p><strong>metric</strong> (<em>callable function reference</em>) – similarity metric function</p></li>
</ul>
</dd>
<dt class="field-even">Return S</dt>
<dd class="field-even"><p>Image similarity image</p>
</dd>
<dt class="field-odd">Rtype S</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.similarity(T)</span></code> is an image where each pixel is the <code class="docutils literal notranslate"><span class="pre">zncc</span></code>
similarity of the template <code class="docutils literal notranslate"><span class="pre">T</span></code> (M,M) to the (M,M) neighbourhood
surrounding the corresonding input pixel in image.  <code class="docutils literal notranslate"><span class="pre">S</span></code> is same
size as image.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.similarity(T,</span> <span class="pre">metric)</span></code> as above but the similarity metric is
specified by the function <code class="docutils literal notranslate"><span class="pre">metric</span></code> which can be any of &#64;sad, &#64;ssd,
&#64;ncc, &#64;zsad, &#64;zssd.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>For NCC and ZNCC the maximum in S corresponds to the most likely
template location.  For SAD, SSD, ZSAD and ZSSD the minimum value
corresponds to the most likely location.</p></li>
<li><p>Similarity is not computed for those pixels where the template
crosses the image boundary, and these output pixels are set
to NaN.</p></li>
<li><p>The ZNCC function is a MEX file and therefore the fastest</p></li>
<li><p>User provided similarity metrics can be used, the function
accepts two regions and returns a scalar similarity score.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">References</dt>
<dd class="field-odd"><ul class="simple">
<li><p>Robotics, Vision &amp; Control, Section 12.4, P. Corke,
Springer 2011.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.smooth">
<code class="sig-name descname">smooth</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">sigma</span></em>, <em class="sig-param"><span class="n">hw</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">optmode</span><span class="o">=</span><span class="default_value">'same'</span></em>, <em class="sig-param"><span class="n">optboundary</span><span class="o">=</span><span class="default_value">'fill'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.smooth" title="Permalink to this definition">¶</a></dt>
<dd><p>Smooth image</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sigma</strong> (<em>float</em>) – standard deviation of the Gaussian kernel</p></li>
<li><p><strong>hw</strong> (<em>float</em>) – half-width of the kernel</p></li>
<li><p><strong>opt</strong> (<em>string</em>) – convolution options np.convolve (see below)</p></li>
</ul>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>Image with smoothed image pixels</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.smooth(sigma)</span></code> is the image after convolution with a Gaussian
kernel of standard deviation <code class="docutils literal notranslate"><span class="pre">sigma</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.smooth(sigma,</span> <span class="pre">hw)</span></code> as above with kernel half-width <code class="docutils literal notranslate"><span class="pre">hw</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.smooth(sigma,</span> <span class="pre">opt)</span></code> as above with options passed to np.convolve</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Options</dt>
<dd class="field-odd"><ul class="simple">
<li><p>‘full’    returns the full 2-D convolution (default)</p></li>
<li><p>‘same’    returns OUT the same size as IM</p></li>
<li><p>‘valid’   returns  the valid pixels only, those where the kernel
does not exceed the bounds of the image.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>By default (option ‘full’) the returned image is larger than the
passed image.</p></li>
<li><p>Smooths all planes of the input image.</p></li>
<li><p>The Gaussian kernel has a unit volume.</p></li>
<li><p>If input image is integer it is converted to float, convolved,
then converted back to integer.</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.ssd">
<code class="sig-name descname">ssd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">im2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.ssd" title="Permalink to this definition">¶</a></dt>
<dd><p>Sum of squared differences</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>im2</strong> (<em>numpy array</em>) – image 2</p>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>ssd</p>
</dd>
<dt class="field-odd">Rtype out</dt>
<dd class="field-odd"><p>scalar</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.ssd(im2)</span></code> is the sum of squared differences between the two
equally sized image patches image and <code class="docutils literal notranslate"><span class="pre">im2</span></code>.  The result M is a
scalar that indicates image similarity, a value of 0 indicates
identical pixel patterns and is increasingly positive as image
dissimilarity increases.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.window">
<code class="sig-name descname">window</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">se</span></em>, <em class="sig-param"><span class="n">func</span></em>, <em class="sig-param"><span class="n">opt</span><span class="o">=</span><span class="default_value">'border'</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.window" title="Permalink to this definition">¶</a></dt>
<dd><p>Generalized spatial operator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>se</strong> (<em>numpy array</em>) – structuring element</p></li>
<li><p><strong>func</strong> – function to operate</p></li>
<li><p><strong>opt</strong> (<em>string</em>) – border option</p></li>
</ul>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>Image after function has operated on every pixel by func</p>
</dd>
<dt class="field-odd">Rtype out</dt>
<dd class="field-odd"><p>Image instance</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.window(se,</span> <span class="pre">func)</span></code> is an image where each pixel is the result of
applying the function <code class="docutils literal notranslate"><span class="pre">func</span></code> to a neighbourhood centred on the
corresponding pixel in image. The neighbourhood is defined by the
size of the structuring element <code class="docutils literal notranslate"><span class="pre">se</span></code> which should have odd side
lengths. The elements in the neighbourhood corresponding to non-zero
elements in <code class="docutils literal notranslate"><span class="pre">se</span></code> are packed into a vector (in column order from top
left) and passed to the specified callable function <code class="docutils literal notranslate"><span class="pre">func</span></code>. The
return value of <code class="docutils literal notranslate"><span class="pre">func</span></code> becomes the corresponding pixel value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IM.window(se,</span> <span class="pre">func,</span> <span class="pre">opt)</span></code> as above but performance of edge pixels
can be controlled.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Options</dt>
<dd class="field-odd"><ul class="simple">
<li><p>‘replicate’     the border value is replicated (default)</p></li>
<li><p>‘none’          pixels beyond the border are not included in the
window</p></li>
<li><p>‘trim’          output is not computed for pixels where the
structuring element crosses the image border, hence output image
has reduced dimensions TODO</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The structuring element should have an odd side length.</p></li>
<li><p>Is slow since the function <code class="docutils literal notranslate"><span class="pre">func</span></code> must be invoked once for
every output pixel.</p></li>
<li><p>The input can be logical, uint8, uint16, float or double, the
output is always double</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.zncc">
<code class="sig-name descname">zncc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">im2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.zncc" title="Permalink to this definition">¶</a></dt>
<dd><p>Zero-mean normalized cross correlation</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>im2</strong> – image 2 :type im2: numpy array :return out: zncc :rtype</p>
</dd>
</dl>
<p>out: scalar</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.zncc(im2)</span></code> is the zero-mean normalized cross-correlation
between the two equally sized image patches image and <code class="docutils literal notranslate"><span class="pre">im2</span></code>.  The
result is a scalar in the interval -1 to 1 that indicates similarity.
A value of 1 indicates identical pixel patterns.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">zncc</span></code> similarity measure is invariant to affine changes
in image intensity (brightness offset and scale).</p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.zsad">
<code class="sig-name descname">zsad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">im2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.zsad" title="Permalink to this definition">¶</a></dt>
<dd><p>Zero-mean sum of absolute differences</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>im2</strong> (<em>numpy array</em>) – image 2</p>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>zsad</p>
</dd>
<dt class="field-odd">Rtype out</dt>
<dd class="field-odd"><p>scalar</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.zsad(im2)</span></code> is the zero-mean sum of absolute differences between
the two equally sized image patches image and <code class="docutils literal notranslate"><span class="pre">im2</span></code>. The result is
a scalar that indicates image similarity, a value of 0 indicates
identical pixel patterns and is increasingly positive as image
dissimilarity increases.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">zsad</span></code> similarity measure is invariant to changes in image</p></li>
</ul>
<p>brightness offset.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="machinevisiontoolbox.Image.zssd">
<code class="sig-name descname">zssd</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">im2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#machinevisiontoolbox.Image.zssd" title="Permalink to this definition">¶</a></dt>
<dd><p>Zero-mean sum of squared differences</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>im2</strong> (<em>numpy array</em>) – image 2</p>
</dd>
<dt class="field-even">Return out</dt>
<dd class="field-even"><p>zssd</p>
</dd>
<dt class="field-odd">Rtype out</dt>
<dd class="field-odd"><p>scalar</p>
</dd>
</dl>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IM.zssd(im1,</span> <span class="pre">im2)</span></code> is the zero-mean sum of squared differences
between the two equally sized image patches image and <code class="docutils literal notranslate"><span class="pre">im2</span></code>.  The
result is a scalar that indicates image similarity, a value of 0
indicates identical pixel patterns and is increasingly positive as
image dissimilarity increases.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">zssd</span></code> similarity measure is invariant to changes in image
brightness offset.</p></li>
</ul>
</div>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="morph.html" class="btn btn-neutral float-right" title="Morphological operations" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="imagecolor.html" class="btn btn-neutral float-left" title="Color operations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 
      <span class="lastupdated">
        Last updated on 28-Jan-2021.
      </span>

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>